{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "height = 128\n",
    "\n",
    "X_train   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "y_train = []\n",
    "X_test   =  np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 16384)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/Users/boyaronur/Desktop/AR_DB/resized_sketch/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "#print(directory)\n",
    "#print(directory_dir)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train.append(directory_dir[j])\n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/AR_DB/resized_photos/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "#print(directory)\n",
    "#print(directory_dir)\n",
    "for i in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[i], as_gray=True)\n",
    "    X_test[i,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_test.append(directory_dir[i])\n",
    "    \n",
    "len(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 16384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(123,128,128,1)\n",
    "X_test = X_test.reshape(123,128,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.arange(0,123,1)\n",
    "y_test = np.arange(0,123,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#y_train = pd.factorize(y_train)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 128, 128, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate(X_train, X_test[0:30])\n",
    "y_train = np.concatenate(y_train, y_test[0:30])\n",
    "\n",
    "X_test = X_test[30:123]\n",
    "y_test = y_test[30:123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "# Random Shifts\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 128, 128)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 128, 128)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "datagen.fit(X_train)\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=123):\n",
    "    print('hello')\n",
    "    break\n",
    "        \n",
    "X_train_more = np.concatenate((X_train, X_batch), axis=0)\n",
    "y_batch = np.arange(0,123,1)\n",
    "y_batch = to_categorical(y_batch)\n",
    "y_train_more = np.concatenate((y_train, y_batch), axis = 0)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "datagen.fit(X_train)\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=123):\n",
    "    print('hello')\n",
    "    break\n",
    "\n",
    "X_train_more = np.concatenate((X_train_more, X_batch), axis=0)\n",
    "y_batch = np.arange(0,123,1)\n",
    "y_batch = to_categorical(y_batch)\n",
    "y_train_more = np.concatenate((y_train_more, y_batch), axis = 0)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "datagen.fit(X_train)\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=123):\n",
    "    print('hello')\n",
    "    break\n",
    "\n",
    "X_train_more = np.concatenate((X_train_more, X_batch), axis=0)\n",
    "y_batch = np.arange(0,123,1)\n",
    "y_batch = to_categorical(y_batch)\n",
    "y_train_more = np.concatenate((y_train_more, y_batch), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 123)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_more.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_more = X_train_more.reshape(492,128,128,1)\n",
    "X_test = X_test.reshape(123,128,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2ffa3be0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_batch[0].reshape(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/boyaronur/.conda/envs/untitled1/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 32)      18464     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 492032)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 123)               60520059  \n",
      "=================================================================\n",
      "Total params: 60,539,163\n",
      "Trainable params: 60,539,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(128,128,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(123, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_absolute_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/boyaronur/.conda/envs/untitled1/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 492 samples, validate on 123 samples\n",
      "Epoch 1/500\n",
      "492/492 [==============================] - 52s 106ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 2/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 3/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 4/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 5/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 6/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 7/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 8/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 9/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 10/500\n",
      "492/492 [==============================] - 48s 97ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 11/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 12/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 13/500\n",
      "492/492 [==============================] - 48s 97ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 14/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 15/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 16/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 17/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 18/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 19/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 20/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 21/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 22/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 23/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 24/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 25/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 26/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 27/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 28/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 29/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 30/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 31/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 32/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 33/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 34/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 35/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 36/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 37/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 38/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 39/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 40/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 41/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 42/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 43/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 44/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 45/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 46/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 47/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 48/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 49/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 50/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 51/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 52/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 53/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 54/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 55/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 56/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 57/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 58/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 60/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 61/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 62/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 63/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 64/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 65/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 66/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 67/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 68/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 69/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 70/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 71/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 72/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 73/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 74/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 75/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 76/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 77/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 78/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 79/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 80/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 81/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 82/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 83/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 84/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 85/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 86/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 87/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 88/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 89/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 90/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 91/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 92/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 93/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 94/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 95/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 96/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 97/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 98/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 99/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 100/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 101/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 102/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 103/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 104/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 105/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 106/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 107/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 108/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 109/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 110/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 111/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 112/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 113/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 114/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 115/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 116/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 117/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 118/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 120/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 121/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 122/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 123/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 124/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 125/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 126/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 127/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 128/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 129/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 130/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 131/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 132/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 133/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 134/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 135/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 136/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 137/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 138/500\n",
      "492/492 [==============================] - 48s 98ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 139/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 140/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 141/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 142/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 143/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 144/500\n",
      "492/492 [==============================] - 48s 97ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 145/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 146/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 147/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 148/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 149/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 150/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 151/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 152/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 153/500\n",
      "492/492 [==============================] - 46s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 154/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 155/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 156/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 157/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 158/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 159/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 160/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0102 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 161/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 162/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 163/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 164/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 165/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 166/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 167/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 168/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 169/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 170/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 171/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 172/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 173/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 174/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 175/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 176/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 177/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 178/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 180/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 181/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 182/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 183/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 184/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 185/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 186/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 187/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 188/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 189/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 190/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 191/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 192/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 193/500\n",
      "492/492 [==============================] - 48s 97ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 194/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 195/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 196/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 197/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 198/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 199/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 200/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 201/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 202/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 203/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 204/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 205/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 206/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 207/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 208/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 209/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 210/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 211/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 212/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 213/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 214/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 215/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 216/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 217/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 218/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 219/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 220/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 221/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 222/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 223/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 224/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 225/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 226/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 227/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 228/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 229/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 230/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 231/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 232/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 233/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 234/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 235/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 236/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 237/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 238/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 240/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 241/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 242/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 243/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 244/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 245/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 246/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 247/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 248/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 249/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 250/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 251/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 252/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 253/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 254/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 255/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 256/500\n",
      "492/492 [==============================] - 48s 97ms/step - loss: 0.0161 - acc: 0.0122 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 257/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 258/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 259/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 260/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 261/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 262/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 263/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 264/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 265/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 266/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 267/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 268/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 269/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 270/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 271/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 272/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 273/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 274/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 275/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 276/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 277/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 278/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 279/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 280/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 281/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 282/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 283/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 284/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 285/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 286/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 287/500\n",
      "492/492 [==============================] - 48s 98ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 288/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 289/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 290/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 291/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 292/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 293/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 294/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 295/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 296/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 297/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 298/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 300/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 301/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 302/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 303/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 304/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 305/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 306/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 307/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 308/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 309/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 310/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 311/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 312/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 313/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 314/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 315/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 316/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 317/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 318/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 319/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 320/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 321/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 322/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 323/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 324/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 325/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 326/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 327/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 328/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 329/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 330/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 331/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 332/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 333/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 334/500\n",
      "492/492 [==============================] - 46s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 335/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 336/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 337/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 338/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 339/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 340/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0142 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 341/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 342/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 343/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 344/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 345/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 346/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 347/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 348/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 349/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 350/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 351/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0163 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 352/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 353/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 354/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 355/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 356/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 357/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 358/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 360/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 361/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 362/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 363/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 364/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 365/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 366/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 367/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 368/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 369/500\n",
      "492/492 [==============================] - 46s 93ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 370/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 371/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 372/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 373/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 374/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 375/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 376/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 377/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 378/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 379/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 380/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 381/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 382/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 383/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 384/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 385/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 386/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 387/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 388/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 389/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 390/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 391/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 392/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 393/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 394/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 395/500\n",
      "492/492 [==============================] - 48s 97ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 396/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 397/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 398/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 399/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 400/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 401/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 402/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 403/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 404/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 405/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 406/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 407/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 408/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 409/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 410/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 411/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 412/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 413/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 414/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 415/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 416/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 417/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 418/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 420/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 421/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 422/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 423/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 424/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 425/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 426/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 427/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 428/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 429/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 430/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 431/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 432/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 433/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 434/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 435/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 436/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 437/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 438/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 439/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 440/500\n",
      "492/492 [==============================] - 47s 96ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 441/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 442/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 443/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 444/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 445/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 446/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0183 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 447/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 448/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 449/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 450/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 451/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 452/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 453/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 454/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 455/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 456/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 457/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 458/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 459/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 460/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 461/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 462/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 463/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 464/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 465/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 466/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 467/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 468/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 469/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 470/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 471/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 472/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 473/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 474/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 475/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 476/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 477/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 478/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 480/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 481/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 482/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 483/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 484/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 485/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 486/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 487/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 488/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 489/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 490/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 491/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 492/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 493/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 494/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 495/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 496/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 497/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 498/500\n",
      "492/492 [==============================] - 47s 95ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 499/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n",
      "Epoch 500/500\n",
      "492/492 [==============================] - 46s 94ms/step - loss: 0.0161 - acc: 0.0203 - val_loss: 0.0160 - val_acc: 0.0163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3014e588>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_more, y_train_more, validation_data=(X_test, y_test), epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6443949e-36,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        3.5434842e-29, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 9.9974865e-01, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0163858e-26, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.5129408e-04,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.9711288e-33,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.4223234e-38,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
