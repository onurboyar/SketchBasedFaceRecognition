{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "height = 128\n",
    "\n",
    "X_train_AR   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "y_train_AR = []\n",
    "X_test_AR   =  np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "y_test_AR = []\n",
    "\n",
    "X_test_Flip   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "\n",
    "X_test_Rotate   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "\n",
    "X_test_Zoom_In_1   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "\n",
    "X_test_Zoom_In_2   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "X_train_Flip   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "y_train_Flip = []\n",
    "\n",
    "X_train_Rotate   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "y_train_Rotate = []\n",
    "\n",
    "X_train_Zoom_In_1   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "y_train_Zoom_1 = []\n",
    "\n",
    "X_train_Zoom_In_2   = np.ndarray(shape=(123, height*width), dtype=np.float64)\n",
    "y_train_Zoom_2 = []\n",
    "\n",
    "#CUHK\n",
    "\n",
    "X_test_CUHK   =  np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "y_test_CUHK = []\n",
    "\n",
    "X_test_Flip_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "\n",
    "X_test_Rotate_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "\n",
    "X_test_Zoom_In_1_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "\n",
    "X_test_Zoom_In_2_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "\n",
    "\n",
    "X_train_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "y_train_CUHK = []\n",
    "X_test_CUHK   =  np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "y_test_CUHK = []\n",
    "\n",
    "X_train_Flip_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "y_train_Flip_CUHK = []\n",
    "\n",
    "X_train_Rotate_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "y_train_Rotate_CUHK = []\n",
    "\n",
    "X_train_Zoom_In_1_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "y_train_Zoom_1_CUHK = []\n",
    "\n",
    "X_train_Zoom_In_2_CUHK   = np.ndarray(shape=(188, height*width), dtype=np.float64)\n",
    "y_train_Zoom_2_CUHK = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST\n",
    "\n",
    "#directory = '/Users/boyaronur/Desktop/FACE/resized_photos_AR_128/' \n",
    "directory = '/Users/boyaronur/Desktop/FACE/Photo_Gray_AR/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for i in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[i], as_gray=True)\n",
    "    X_test_AR[i,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_test_AR.append(directory_dir)\n",
    "#### TRAIN\n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/resized_sketch_AR_128/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_AR[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_AR.append(directory_dir[j])\n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/AR_Sketch_Aug_Flip/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Flip[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_Flip.append(directory_dir[j])\n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/AR_Sketch_Aug_Zoom_In_1.5/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Zoom_In_1[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_Zoom_1.append(directory_dir[j])\n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/AR_Sketch_Aug_Zoom_In_2.5/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Zoom_In_2[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_Zoom_2.append(directory_dir[j])\n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/AR_Sketch_Aug_Rotate_90/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Rotate[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_Rotate.append(directory_dir[j])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### AUGMENTED TEST DATA - AR   \n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/AR_Photo_Aug_Rotate_90/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_test_Rotate[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    #y_train_Rotate.append(directory_dir[j])\n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/AR_Photo_Aug_Flip/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Flip[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    #y_train_Rotate.append(directory_dir[j])\n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/AR_Photo_Aug_Zoom_In_1.5/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_test_Zoom_In_1[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    #y_train_Rotate.append(directory_dir[j])\n",
    "    \n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/AR_Photo_Aug_Zoom_In_2.5/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_test_Zoom_In_2[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    #y_train_Rotate.append(directory_dir[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_CUHK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CUHK #####\n",
    "    \n",
    "#### TEST\n",
    "\n",
    "#directory = '/Users/boyaronur/Desktop/FACE/resized_photos_CUHK_128/' \n",
    "directory = '/Users/boyaronur/Desktop/FACE/Photo_Gray_CUHK/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for i in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[i], as_gray=True)\n",
    "    X_test_CUHK[i,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_test_CUHK.append(directory_dir)\n",
    "#### TRAIN\n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/resized_sketch_CUHK_128/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_CUHK.append(directory_dir[j])\n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/CUHK_Sketch_Aug_Flip/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Flip_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_Flip_CUHK.append(directory_dir[j])\n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/CUHK_Sketch_Aug_Zoom_In_1.5/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Zoom_In_1_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_Zoom_1_CUHK.append(directory_dir[j])\n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/CUHK_Sketch_Aug_Zoom_In_2.5/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Zoom_In_2_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_Zoom_2_CUHK.append(directory_dir[j])\n",
    "    \n",
    "directory = '/Users/boyaronur/Desktop/FACE/CUHK_Sketch_Aug_Rotate_90/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Rotate_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    y_train_Rotate_CUHK.append(directory_dir[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUGMENTED TEST DATA - CUHK\n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/CUHK_Photo_Aug_Rotate_90/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_test_Rotate_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    #y_train_Rotate.append(directory_dir[j])\n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/CUHK_Photo_Aug_Flip/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_train_Flip_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    #y_train_Rotate.append(directory_dir[j])\n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/CUHK_Photo_Aug_Zoom_In_1.5/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_test_Zoom_In_1_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    #y_train_Rotate.append(directory_dir[j])\n",
    "    \n",
    "\n",
    "directory = '/Users/boyaronur/Desktop/FACE/CUHK_Photo_Aug_Zoom_In_2.5/' \n",
    "directory_dir  = os.listdir(directory)\n",
    "directory_dir = sorted(directory_dir)\n",
    "os.chdir(directory)\n",
    "for j in range(len(directory_dir)):\n",
    "    img = io.imread(directory_dir[j], as_gray=True)\n",
    "    X_test_Zoom_In_2_CUHK[j,:] = np.array(img, dtype='float64').flatten()\n",
    "    #y_train_Rotate.append(directory_dir[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 16384)\n",
      "(188, 16384)\n",
      "(188, 16384)\n",
      "(188, 16384)\n",
      "(188, 16384)\n",
      "(188, 16384)\n",
      "(188, 16384)\n",
      "(188, 16384)\n",
      "(188, 16384)\n",
      "(188, 16384)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_CUHK.shape)\n",
    "print(X_train_CUHK.shape)\n",
    "print(X_train_Flip_CUHK.shape)\n",
    "print(X_train_Rotate_CUHK.shape)\n",
    "print(X_train_Zoom_In_1_CUHK.shape)\n",
    "print(X_train_Zoom_In_2_CUHK.shape)\n",
    "\n",
    "print(X_test_Flip_CUHK.shape)\n",
    "print(X_test_Rotate_CUHK.shape)\n",
    "print(X_test_Zoom_In_1_CUHK.shape)\n",
    "print(X_test_Zoom_In_2_CUHK.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor   = np.ndarray(shape=(123*5 + 188*5  + 70*5 + 100*5, height*width), dtype=np.float64)\n",
    "#X_tensor_test = np.ndarray(shape=(685, height*width), dtype=np.float64)\n",
    "X_tensor = X_tensor.reshape(2405,128,128,1)\n",
    "#X_tensor_test = X_tensor_test.reshape(685,128,128,1)\n",
    "\n",
    "#X_test_AR = X_test_AR.reshape(123,128,128,1)\n",
    "\n",
    "X_tensor[0:123] = X_train_AR.reshape(123,128,128,1)\n",
    "X_tensor[123:246] = X_train_Flip.reshape(123,128,128,1)\n",
    "X_tensor[246:369] = X_train_Rotate.reshape(123,128,128,1)\n",
    "X_tensor[369:492] = X_train_Zoom_In_1.reshape(123,128,128,1)\n",
    "X_tensor[492:615] = X_train_Zoom_In_2.reshape(123,128,128,1)\n",
    "X_tensor[615:685] = X_test_AR[0:70].reshape(70,128,128,1)\n",
    "X_tensor[685:755] = X_test_Flip[0:70].reshape(70,128,128,1)\n",
    "X_tensor[755:825] = X_test_Rotate[0:70].reshape(70,128,128,1)\n",
    "X_tensor[825:895] = X_test_Zoom_In_1[0:70].reshape(70,128,128,1)\n",
    "X_tensor[895:965] = X_test_Zoom_In_2[0:70].reshape(70,128,128,1)\n",
    "\n",
    "X_tensor[965:1153] = X_train_CUHK.reshape(188,128,128,1)\n",
    "X_tensor[1153:1341] = X_train_Flip_CUHK.reshape(188,128,128,1)\n",
    "X_tensor[1341:1529] = X_train_Rotate_CUHK.reshape(188,128,128,1)\n",
    "X_tensor[1529:1717] = X_train_Zoom_In_1_CUHK.reshape(188,128,128,1)\n",
    "X_tensor[1717:1905] = X_train_Zoom_In_2_CUHK.reshape(188,128,128,1)\n",
    "X_tensor[1905:2005] = X_test_CUHK[0:100].reshape(100,128,128,1)\n",
    "X_tensor[1905:2005] = X_test_Flip_CUHK[0:100].reshape(100,128,128,1)\n",
    "X_tensor[2005:2105] = X_test_Rotate_CUHK[0:100].reshape(100,128,128,1)\n",
    "X_tensor[2105:2205] = X_test_Zoom_In_1_CUHK[0:100].reshape(100,128,128,1)\n",
    "X_tensor[2205:2305] = X_test_Zoom_In_2_CUHK[0:100].reshape(100,128,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2405, 128, 128, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_tensor_CUHK   = np.ndarray(shape=(685, height*width), dtype=np.float64)\n",
    "X_tensor_CUHK = X_tensor_CUHK.reshape(685,128,128,1)\n",
    "X_test_CUHK = X_test_CUHK.reshape(123,128,128,1)\n",
    "\n",
    "X_tensor_CUHK[0:123] = X_train_CUHK.reshape(123,128,128,1)\n",
    "X_tensor_CUHK[123:246] = X_train_Flip_CUHK.reshape(123,128,128,1)\n",
    "X_tensor_CUHK[246:369] = X_train_Rotate_CUHK.reshape(123,128,128,1)\n",
    "X_tensor_CUHK[369:492] = X_train_Zoom_In_1_CUHK.reshape(123,128,128,1)\n",
    "X_tensor_CUHK[492:615] = X_train_Zoom_In_2_CUHK.reshape(123,128,128,1)\n",
    "X_tensor_CUHK[615:685] = X_test_CUHK[0:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "y_labels = np.zeros(2405)\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "y_labels[0:123] = np.arange(0,123,1)\n",
    "y_labels[123:246] = np.arange(0,123,1)\n",
    "y_labels[246:369] = np.arange(0,123,1)\n",
    "y_labels[369:492] = np.arange(0,123,1)\n",
    "y_labels[492:615] = np.arange(0,123,1)\n",
    "y_labels[615:685] = np.arange(0,70,1)\n",
    "y_labels[685:755] = np.arange(0,70,1)\n",
    "y_labels[755:825] = np.arange(0,70,1)\n",
    "y_labels[825:895] = np.arange(0,70,1)\n",
    "y_labels[895:965] = np.arange(0,70,1)\n",
    "\n",
    "y_labels[965:1153] = np.arange(123,311,1)\n",
    "y_labels[1153:1341] = np.arange(123,311,1)\n",
    "y_labels[1341:1529] = np.arange(123,311,1)\n",
    "y_labels[1529:1717] = np.arange(123,311,1)\n",
    "y_labels[1717:1905] = np.arange(123,311,1)\n",
    "\n",
    "y_labels[1905:2005] = np.arange(123,223,1)\n",
    "y_labels[2005:2105] = np.arange(123,223,1)\n",
    "y_labels[2105:2205] = np.arange(123,223,1)\n",
    "y_labels[2205:2305] = np.arange(123,223,1)\n",
    "y_labels[2305:2405] = np.arange(123,223,1)\n",
    "\n",
    "\n",
    "y_labels = to_categorical(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2405, 128, 128, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.zeros(311)\n",
    "y_test = np.arange(0,311,1)\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_test_1 = y_test[70:123]\n",
    "y_test_2 = y_test[223:311]\n",
    "\n",
    "y_test_enc = np.ndarray(shape = (141, 311))\n",
    "y_test_enc[0:53] = y_test_1\n",
    "y_test_enc[53:141] = y_test_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 16384)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_CUHK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all = np.ndarray(shape = (141, 128*128))\n",
    "X_test_all[0:53] = X_test_AR[70:123]\n",
    "X_test_all[53:141] = X_test_CUHK[100:188]\n",
    "X_test_all = X_test_all.reshape(141,128,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2405, 128, 128, 1)\n",
      "(2405, 311)\n",
      "(141, 128, 128, 1)\n",
      "(141, 311)\n"
     ]
    }
   ],
   "source": [
    "print(X_tensor.shape)\n",
    "print(y_labels.shape)\n",
    "print(X_test_all.shape)\n",
    "print(y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 126, 126, 6)       60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 63, 63, 6)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 63, 63, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 61, 61, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 311)               155811    \n",
      "=================================================================\n",
      "Total params: 1,332,387\n",
      "Trainable params: 1,332,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, AveragePooling2D\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,1)))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "\n",
    "#model.add(Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=311, activation = 'softmax')) #10 yerine 311, bence cok sacma\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/boyaronur/.conda/envs/untitled1/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2405 samples, validate on 141 samples\n",
      "Epoch 1/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 5.8247 - acc: 0.0033 - val_loss: 5.7581 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 5.7204 - acc: 0.0017 - val_loss: 5.8521 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 5.6828 - acc: 0.0037 - val_loss: 8.8212 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 5.6644 - acc: 0.0029 - val_loss: 7.2700 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "2405/2405 [==============================] - 25s 11ms/step - loss: 5.6451 - acc: 0.0021 - val_loss: 6.0084 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 5.6390 - acc: 0.0025 - val_loss: 5.9800 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 5.6344 - acc: 0.0017 - val_loss: 6.0399 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 5.6303 - acc: 0.0029 - val_loss: 6.2107 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 5.6302 - acc: 0.0029 - val_loss: 7.2250 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 5.6261 - acc: 0.0033 - val_loss: 6.8863 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 5.6267 - acc: 8.3160e-04 - val_loss: 6.2843 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 5.6267 - acc: 0.0029 - val_loss: 6.1464 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 5.6253 - acc: 0.0021 - val_loss: 6.2074 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 5.6231 - acc: 0.0033 - val_loss: 6.2863 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 5.6216 - acc: 0.0046 - val_loss: 6.9238 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "2405/2405 [==============================] - 28s 12ms/step - loss: 5.6185 - acc: 0.0042 - val_loss: 6.7452 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 5.6145 - acc: 0.0037 - val_loss: 6.5727 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 5.6068 - acc: 0.0050 - val_loss: 6.9357 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 5.5947 - acc: 0.0058 - val_loss: 8.3420 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 5.5950 - acc: 0.0042 - val_loss: 9.1642 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "2405/2405 [==============================] - 23s 9ms/step - loss: 5.5863 - acc: 0.0062 - val_loss: 7.2150 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 5.5501 - acc: 0.0067 - val_loss: 11.7552 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 5.5906 - acc: 0.0083 - val_loss: 10.5111 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 5.5499 - acc: 0.0100 - val_loss: 11.3731 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 5.4153 - acc: 0.0166 - val_loss: 15.2380 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 5.3522 - acc: 0.0158 - val_loss: 12.3539 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 5.1789 - acc: 0.0245 - val_loss: 14.7966 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 5.0049 - acc: 0.0279 - val_loss: 13.5088 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 4.8005 - acc: 0.0391 - val_loss: 13.7005 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 4.6122 - acc: 0.0449 - val_loss: 13.3987 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 4.3872 - acc: 0.0615 - val_loss: 14.7088 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 4.0809 - acc: 0.0919 - val_loss: 15.0903 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 3.8911 - acc: 0.1173 - val_loss: 14.5760 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 3.5811 - acc: 0.1701 - val_loss: 15.3661 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 3.2664 - acc: 0.2129 - val_loss: 14.8823 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 3.0135 - acc: 0.2715 - val_loss: 15.2634 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 2.7786 - acc: 0.3189 - val_loss: 15.5771 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 2.5704 - acc: 0.3630 - val_loss: 14.6185 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 2.3246 - acc: 0.4141 - val_loss: 14.8642 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 2.1683 - acc: 0.4624 - val_loss: 15.2738 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 2.0585 - acc: 0.4894 - val_loss: 15.0367 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.8462 - acc: 0.5405 - val_loss: 15.3484 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 1.7243 - acc: 0.5755 - val_loss: 15.3426 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "2405/2405 [==============================] - 23s 9ms/step - loss: 1.6327 - acc: 0.5954 - val_loss: 15.5790 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 1.6411 - acc: 0.5979 - val_loss: 15.1165 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 1.3862 - acc: 0.6628 - val_loss: 15.1208 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 1.3190 - acc: 0.6873 - val_loss: 15.3053 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 1.2955 - acc: 0.6865 - val_loss: 15.3412 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 1.2501 - acc: 0.7019 - val_loss: 15.4134 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 1.1631 - acc: 0.7222 - val_loss: 15.5539 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c5c6f6400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "model.fit(X_tensor, y_labels, validation_data=(X_test_all, y_test_enc), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 965 samples, validate on 53 samples\n",
      "Epoch 1/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 3.0926 - acc: 0.2311 - val_loss: 5.5242 - val_acc: 0.0000e+00\n",
      "Epoch 2/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 2.8829 - acc: 0.2798 - val_loss: 6.1651 - val_acc: 0.0000e+00\n",
      "Epoch 3/450\n",
      "965/965 [==============================] - 9s 10ms/step - loss: 2.7448 - acc: 0.3140 - val_loss: 5.7583 - val_acc: 0.0000e+00\n",
      "Epoch 4/450\n",
      "965/965 [==============================] - 8s 9ms/step - loss: 2.5538 - acc: 0.3451 - val_loss: 5.2329 - val_acc: 0.0000e+00\n",
      "Epoch 5/450\n",
      "965/965 [==============================] - 9s 10ms/step - loss: 2.4461 - acc: 0.3782 - val_loss: 10.3907 - val_acc: 0.0000e+00\n",
      "Epoch 6/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 2.3392 - acc: 0.4052 - val_loss: 6.6779 - val_acc: 0.0000e+00\n",
      "Epoch 7/450\n",
      "965/965 [==============================] - 9s 10ms/step - loss: 2.1687 - acc: 0.4290 - val_loss: 4.7185 - val_acc: 0.0000e+00\n",
      "Epoch 8/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 2.0550 - acc: 0.4736 - val_loss: 5.6384 - val_acc: 0.0000e+00\n",
      "Epoch 9/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 1.9561 - acc: 0.4798 - val_loss: 5.3808 - val_acc: 0.0000e+00\n",
      "Epoch 10/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 1.8603 - acc: 0.5098 - val_loss: 9.1787 - val_acc: 0.0000e+00\n",
      "Epoch 11/450\n",
      "965/965 [==============================] - 9s 10ms/step - loss: 1.7799 - acc: 0.5233 - val_loss: 5.0353 - val_acc: 0.0000e+00\n",
      "Epoch 12/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 1.6526 - acc: 0.5565 - val_loss: 4.7213 - val_acc: 0.0189\n",
      "Epoch 13/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 1.5751 - acc: 0.5896 - val_loss: 6.6235 - val_acc: 0.0000e+00\n",
      "Epoch 14/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 1.4146 - acc: 0.6394 - val_loss: 6.9186 - val_acc: 0.0000e+00\n",
      "Epoch 15/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 1.3414 - acc: 0.6404 - val_loss: 6.6508 - val_acc: 0.0000e+00\n",
      "Epoch 16/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 1.3885 - acc: 0.6228 - val_loss: 6.6368 - val_acc: 0.0000e+00\n",
      "Epoch 17/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 1.2919 - acc: 0.6601 - val_loss: 4.6369 - val_acc: 0.0189\n",
      "Epoch 18/450\n",
      "965/965 [==============================] - 8s 9ms/step - loss: 1.2609 - acc: 0.6746 - val_loss: 4.7548 - val_acc: 0.0000e+00\n",
      "Epoch 19/450\n",
      "965/965 [==============================] - 8s 9ms/step - loss: 1.1568 - acc: 0.7057 - val_loss: 4.9865 - val_acc: 0.0000e+00\n",
      "Epoch 20/450\n",
      "965/965 [==============================] - 9s 10ms/step - loss: 1.0601 - acc: 0.7326 - val_loss: 8.4874 - val_acc: 0.0000e+00\n",
      "Epoch 21/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 1.0665 - acc: 0.7264 - val_loss: 5.2128 - val_acc: 0.0000e+00\n",
      "Epoch 22/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 1.2882 - acc: 0.6839 - val_loss: 6.4295 - val_acc: 0.0000e+00\n",
      "Epoch 23/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 1.0481 - acc: 0.7316 - val_loss: 8.1706 - val_acc: 0.0000e+00\n",
      "Epoch 24/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 0.9782 - acc: 0.7544 - val_loss: 5.8629 - val_acc: 0.0000e+00\n",
      "Epoch 25/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 0.9420 - acc: 0.7679 - val_loss: 6.7173 - val_acc: 0.0000e+00\n",
      "Epoch 26/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 0.8462 - acc: 0.7948 - val_loss: 6.0913 - val_acc: 0.0000e+00\n",
      "Epoch 27/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 0.8048 - acc: 0.8093 - val_loss: 8.4995 - val_acc: 0.0000e+00\n",
      "Epoch 28/450\n",
      "965/965 [==============================] - 8s 9ms/step - loss: 0.8061 - acc: 0.8114 - val_loss: 6.6981 - val_acc: 0.0000e+00\n",
      "Epoch 29/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 0.8194 - acc: 0.7938 - val_loss: 8.2487 - val_acc: 0.0000e+00\n",
      "Epoch 30/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 0.8393 - acc: 0.7938 - val_loss: 9.1049 - val_acc: 0.0000e+00\n",
      "Epoch 31/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 0.8631 - acc: 0.7855 - val_loss: 6.7847 - val_acc: 0.0000e+00\n",
      "Epoch 32/450\n",
      "965/965 [==============================] - 8s 9ms/step - loss: 0.8318 - acc: 0.7969 - val_loss: 7.9196 - val_acc: 0.0000e+00\n",
      "Epoch 33/450\n",
      "965/965 [==============================] - 8s 8ms/step - loss: 0.8482 - acc: 0.7969 - val_loss: 11.1412 - val_acc: 0.0000e+00\n",
      "Epoch 34/450\n",
      "965/965 [==============================] - 8s 9ms/step - loss: 0.7660 - acc: 0.8166 - val_loss: 9.0973 - val_acc: 0.0000e+00\n",
      "Epoch 35/450\n",
      "965/965 [==============================] - 9s 10ms/step - loss: 0.7381 - acc: 0.8166 - val_loss: 9.7295 - val_acc: 0.0000e+00\n",
      "Epoch 36/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 0.7252 - acc: 0.8311 - val_loss: 8.9073 - val_acc: 0.0000e+00\n",
      "Epoch 37/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 0.6717 - acc: 0.8383 - val_loss: 15.0890 - val_acc: 0.0000e+00\n",
      "Epoch 38/450\n",
      "965/965 [==============================] - 9s 10ms/step - loss: 0.6693 - acc: 0.8435 - val_loss: 10.7996 - val_acc: 0.0000e+00\n",
      "Epoch 39/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 0.6456 - acc: 0.8466 - val_loss: 14.6700 - val_acc: 0.0000e+00\n",
      "Epoch 40/450\n",
      "965/965 [==============================] - 10s 11ms/step - loss: 0.6750 - acc: 0.8352 - val_loss: 14.3705 - val_acc: 0.0000e+00\n",
      "Epoch 41/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 0.6773 - acc: 0.8269 - val_loss: 15.5653 - val_acc: 0.0000e+00\n",
      "Epoch 42/450\n",
      "965/965 [==============================] - 11s 11ms/step - loss: 0.6139 - acc: 0.8435 - val_loss: 15.0763 - val_acc: 0.0000e+00\n",
      "Epoch 43/450\n",
      "965/965 [==============================] - 11s 11ms/step - loss: 0.5886 - acc: 0.8508 - val_loss: 15.2448 - val_acc: 0.0000e+00\n",
      "Epoch 44/450\n",
      "965/965 [==============================] - 10s 10ms/step - loss: 0.5669 - acc: 0.8518 - val_loss: 15.8285 - val_acc: 0.0000e+00\n",
      "Epoch 45/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 0.5917 - acc: 0.8508 - val_loss: 14.1771 - val_acc: 0.0000e+00\n",
      "Epoch 46/450\n",
      "965/965 [==============================] - 9s 10ms/step - loss: 0.5470 - acc: 0.8694 - val_loss: 15.2028 - val_acc: 0.0000e+00\n",
      "Epoch 47/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 0.4990 - acc: 0.8674 - val_loss: 16.0677 - val_acc: 0.0000e+00\n",
      "Epoch 48/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 0.5551 - acc: 0.8632 - val_loss: 15.3199 - val_acc: 0.0000e+00\n",
      "Epoch 49/450\n",
      "965/965 [==============================] - 9s 9ms/step - loss: 0.5110 - acc: 0.8705 - val_loss: 15.8771 - val_acc: 0.0000e+00\n",
      "Epoch 50/450\n",
      " 96/965 [=>............................] - ETA: 7s - loss: 0.4496 - acc: 0.8854"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9ae5a95d4898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_AR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/untitled1/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_tensor, y_labels, validation_data=(X_test_AR[70:123], y_test[70:123]), epochs=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALEX NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/boyaronur/.conda/envs/untitled1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 54, 54, 96)        11712     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 17)                17017     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 17)                0         \n",
      "=================================================================\n",
      "Total params: 28,031,265\n",
      "Trainable params: 28,031,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "#Instantiate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,1), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Passing it to a Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(17))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 16384 into shape (224,224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-56b0de2233df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 16384 into shape (224,224)"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_tensor[1].reshape(224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 6)       60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 63, 63, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 61, 61, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               1728120   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               12100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 311)               31411     \n",
      "=================================================================\n",
      "Total params: 1,772,571\n",
      "Trainable params: 1,772,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,1)))\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=311, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/boyaronur/.conda/envs/untitled1/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2405 samples, validate on 141 samples\n",
      "Epoch 1/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 6.0236 - acc: 8.3160e-04 - val_loss: 7.2781 - val_acc: 0.0071\n",
      "Epoch 2/50\n",
      "2405/2405 [==============================] - 14s 6ms/step - loss: 5.7316 - acc: 0.0046 - val_loss: 6.2208 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 5.6759 - acc: 0.0054 - val_loss: 7.2403 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 5.5868 - acc: 0.0166 - val_loss: 10.5160 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 5.3390 - acc: 0.0249 - val_loss: 11.9564 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 4.9644 - acc: 0.0370 - val_loss: 13.1284 - val_acc: 0.0071\n",
      "Epoch 7/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 4.6200 - acc: 0.0478 - val_loss: 13.5456 - val_acc: 0.0213\n",
      "Epoch 8/50\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 4.2683 - acc: 0.0807 - val_loss: 14.2002 - val_acc: 0.0355\n",
      "Epoch 9/50\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 3.9095 - acc: 0.1102 - val_loss: 15.3345 - val_acc: 0.0142\n",
      "Epoch 10/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 3.5411 - acc: 0.1672 - val_loss: 15.7456 - val_acc: 0.0142\n",
      "Epoch 11/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 3.2502 - acc: 0.2279 - val_loss: 15.7452 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 2.9594 - acc: 0.2952 - val_loss: 15.4534 - val_acc: 0.0213\n",
      "Epoch 13/50\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 2.5497 - acc: 0.3830 - val_loss: 15.4302 - val_acc: 0.0355\n",
      "Epoch 14/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 2.2157 - acc: 0.4599 - val_loss: 15.1267 - val_acc: 0.0426\n",
      "Epoch 15/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 1.9490 - acc: 0.5401 - val_loss: 15.7999 - val_acc: 0.0142\n",
      "Epoch 16/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 1.7324 - acc: 0.6000 - val_loss: 15.9124 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 1.5206 - acc: 0.6486 - val_loss: 15.6856 - val_acc: 0.0142\n",
      "Epoch 18/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 1.2875 - acc: 0.7272 - val_loss: 15.5749 - val_acc: 0.0284\n",
      "Epoch 19/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 1.2598 - acc: 0.7484 - val_loss: 15.9508 - val_acc: 0.0071\n",
      "Epoch 20/50\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.3108 - acc: 0.7547 - val_loss: 15.5644 - val_acc: 0.0142\n",
      "Epoch 21/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 1.1386 - acc: 0.7875 - val_loss: 16.0038 - val_acc: 0.0071\n",
      "Epoch 22/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 1.0503 - acc: 0.8021 - val_loss: 15.9462 - val_acc: 0.0071\n",
      "Epoch 23/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 0.9930 - acc: 0.8237 - val_loss: 16.0723 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 0.9733 - acc: 0.8121 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 1.0390 - acc: 0.8112 - val_loss: 16.0158 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "2405/2405 [==============================] - 15s 6ms/step - loss: 0.9058 - acc: 0.8441 - val_loss: 16.0410 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 0.8085 - acc: 0.8603 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "2405/2405 [==============================] - 18s 7ms/step - loss: 0.7679 - acc: 0.8711 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "2405/2405 [==============================] - 21s 9ms/step - loss: 0.7999 - acc: 0.8657 - val_loss: 16.0740 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 0.8045 - acc: 0.8565 - val_loss: 16.0304 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      " 384/2405 [===>..........................] - ETA: 13s - loss: 0.8316 - acc: 0.8698"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "model.fit(X_tensor, y_labels, validation_data=(X_test_all, y_test_enc), epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet with Regularization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/boyaronur/.conda/envs/untitled1/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/boyaronur/.conda/envs/untitled1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 6)       60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 63, 63, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               1728120   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               12100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 311)               31411     \n",
      "=================================================================\n",
      "Total params: 1,772,571\n",
      "Trainable params: 1,772,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=6, kernel_size=(3, 3),kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu', input_shape=(128,128,1)))\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3),kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=311, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/boyaronur/.conda/envs/untitled1/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2405 samples, validate on 141 samples\n",
      "Epoch 1/50\n",
      "2405/2405 [==============================] - 31s 13ms/step - loss: 5.9431 - acc: 0.0025 - val_loss: 5.9291 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 5.7665 - acc: 0.0033 - val_loss: 7.2151 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "2405/2405 [==============================] - 28s 12ms/step - loss: 5.6902 - acc: 0.0079 - val_loss: 8.0902 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "2405/2405 [==============================] - 30s 13ms/step - loss: 5.5899 - acc: 0.0166 - val_loss: 12.0881 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "2405/2405 [==============================] - 30s 12ms/step - loss: 5.4058 - acc: 0.0279 - val_loss: 15.6279 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 5.1345 - acc: 0.0308 - val_loss: 16.1555 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "2405/2405 [==============================] - 31s 13ms/step - loss: 5.2201 - acc: 0.0216 - val_loss: 16.1592 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "2405/2405 [==============================] - 27s 11ms/step - loss: 4.8912 - acc: 0.0378 - val_loss: 16.1632 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "2405/2405 [==============================] - 33s 14ms/step - loss: 4.5357 - acc: 0.0674 - val_loss: 16.1683 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "2405/2405 [==============================] - 28s 12ms/step - loss: 4.1288 - acc: 0.1364 - val_loss: 16.1751 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "2405/2405 [==============================] - 19s 8ms/step - loss: 3.6470 - acc: 0.2316 - val_loss: 16.1790 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 3.2276 - acc: 0.3119 - val_loss: 15.9625 - val_acc: 0.0142\n",
      "Epoch 13/50\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 2.8035 - acc: 0.4083 - val_loss: 16.1981 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "2405/2405 [==============================] - 18s 7ms/step - loss: 2.4568 - acc: 0.5119 - val_loss: 16.0908 - val_acc: 0.0071\n",
      "Epoch 15/50\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 2.1389 - acc: 0.5871 - val_loss: 15.9895 - val_acc: 0.0071\n",
      "Epoch 16/50\n",
      "2405/2405 [==============================] - 30s 13ms/step - loss: 1.9924 - acc: 0.6162 - val_loss: 15.7603 - val_acc: 0.0284\n",
      "Epoch 17/50\n",
      "2405/2405 [==============================] - 28s 11ms/step - loss: 1.8420 - acc: 0.6769 - val_loss: 15.7651 - val_acc: 0.0284\n",
      "Epoch 18/50\n",
      "2405/2405 [==============================] - 26s 11ms/step - loss: 1.5843 - acc: 0.7459 - val_loss: 15.9945 - val_acc: 0.0142\n",
      "Epoch 19/50\n",
      "2405/2405 [==============================] - 26s 11ms/step - loss: 1.4644 - acc: 0.7755 - val_loss: 15.9948 - val_acc: 0.0142\n",
      "Epoch 20/50\n",
      "2405/2405 [==============================] - 27s 11ms/step - loss: 1.5178 - acc: 0.7626 - val_loss: 15.9955 - val_acc: 0.0142\n",
      "Epoch 21/50\n",
      "2405/2405 [==============================] - 20s 8ms/step - loss: 1.4518 - acc: 0.7784 - val_loss: 15.9952 - val_acc: 0.0142\n",
      "Epoch 22/50\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.3277 - acc: 0.8125 - val_loss: 15.9937 - val_acc: 0.0142\n",
      "Epoch 23/50\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.2859 - acc: 0.8262 - val_loss: 16.0032 - val_acc: 0.0071\n",
      "Epoch 24/50\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 1.2606 - acc: 0.8333 - val_loss: 16.1037 - val_acc: 0.0071\n",
      "Epoch 25/50\n",
      "2405/2405 [==============================] - 18s 8ms/step - loss: 1.2299 - acc: 0.8399 - val_loss: 16.1016 - val_acc: 0.0071\n",
      "Epoch 26/50\n",
      "2405/2405 [==============================] - 24s 10ms/step - loss: 1.2267 - acc: 0.8374 - val_loss: 16.0998 - val_acc: 0.0071\n",
      "Epoch 27/50\n",
      "2405/2405 [==============================] - 33s 14ms/step - loss: 1.2116 - acc: 0.8395 - val_loss: 16.2124 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "2405/2405 [==============================] - 33s 14ms/step - loss: 1.2118 - acc: 0.8395 - val_loss: 16.2106 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "2405/2405 [==============================] - 30s 13ms/step - loss: 1.2328 - acc: 0.8328 - val_loss: 15.9804 - val_acc: 0.0142\n",
      "Epoch 30/50\n",
      "2405/2405 [==============================] - 30s 12ms/step - loss: 1.1952 - acc: 0.8445 - val_loss: 16.2075 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "2405/2405 [==============================] - 28s 12ms/step - loss: 1.1935 - acc: 0.8412 - val_loss: 16.2064 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "2405/2405 [==============================] - 30s 13ms/step - loss: 1.1757 - acc: 0.8449 - val_loss: 15.9817 - val_acc: 0.0071\n",
      "Epoch 33/50\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 1.4882 - acc: 0.7688 - val_loss: 15.8655 - val_acc: 0.0213\n",
      "Epoch 34/50\n",
      "2405/2405 [==============================] - 28s 12ms/step - loss: 1.4305 - acc: 0.7800 - val_loss: 15.8682 - val_acc: 0.0213\n",
      "Epoch 35/50\n",
      "2405/2405 [==============================] - 27s 11ms/step - loss: 1.3180 - acc: 0.8121 - val_loss: 15.9835 - val_acc: 0.0142\n",
      "Epoch 36/50\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 1.1989 - acc: 0.8424 - val_loss: 16.0962 - val_acc: 0.0071\n",
      "Epoch 37/50\n",
      "2405/2405 [==============================] - 26s 11ms/step - loss: 1.1905 - acc: 0.8466 - val_loss: 16.0943 - val_acc: 0.0071\n",
      "Epoch 38/50\n",
      "2405/2405 [==============================] - 25s 10ms/step - loss: 1.1585 - acc: 0.8528 - val_loss: 15.9781 - val_acc: 0.0142\n",
      "Epoch 39/50\n",
      "2405/2405 [==============================] - 26s 11ms/step - loss: 1.1506 - acc: 0.8565 - val_loss: 15.8619 - val_acc: 0.0213\n",
      "Epoch 40/50\n",
      "2405/2405 [==============================] - 25s 11ms/step - loss: 1.1408 - acc: 0.8582 - val_loss: 15.9744 - val_acc: 0.0142\n",
      "Epoch 41/50\n",
      "2405/2405 [==============================] - 25s 10ms/step - loss: 1.1266 - acc: 0.8595 - val_loss: 15.8578 - val_acc: 0.0213\n",
      "Epoch 42/50\n",
      "2405/2405 [==============================] - 25s 10ms/step - loss: 1.1232 - acc: 0.8595 - val_loss: 15.9700 - val_acc: 0.0142\n",
      "Epoch 43/50\n",
      "2405/2405 [==============================] - 25s 10ms/step - loss: 1.1205 - acc: 0.8595 - val_loss: 16.0823 - val_acc: 0.0071\n",
      "Epoch 44/50\n",
      "2405/2405 [==============================] - 25s 11ms/step - loss: 1.1250 - acc: 0.8582 - val_loss: 16.1951 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "2405/2405 [==============================] - 25s 11ms/step - loss: 1.1276 - acc: 0.8574 - val_loss: 15.9653 - val_acc: 0.0142\n",
      "Epoch 46/50\n",
      "2405/2405 [==============================] - 25s 10ms/step - loss: 1.1260 - acc: 0.8574 - val_loss: 16.0780 - val_acc: 0.0071\n",
      "Epoch 47/50\n",
      "2405/2405 [==============================] - 27s 11ms/step - loss: 1.1226 - acc: 0.8582 - val_loss: 15.9628 - val_acc: 0.0142\n",
      "Epoch 48/50\n",
      "2405/2405 [==============================] - 27s 11ms/step - loss: 1.1134 - acc: 0.8595 - val_loss: 15.8471 - val_acc: 0.0213\n",
      "Epoch 49/50\n",
      "2405/2405 [==============================] - 27s 11ms/step - loss: 1.1401 - acc: 0.8503 - val_loss: 15.7517 - val_acc: 0.0213\n",
      "Epoch 50/50\n",
      "2405/2405 [==============================] - 25s 10ms/step - loss: 1.1307 - acc: 0.8549 - val_loss: 15.7321 - val_acc: 0.0284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1ce1b518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "model.fit(X_tensor, y_labels, validation_data=(X_test_all, y_test_enc), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2405 samples, validate on 141 samples\n",
      "Epoch 1/150\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.1149 - acc: 0.8586 - val_loss: 15.9860 - val_acc: 0.0071\n",
      "Epoch 2/150\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.1121 - acc: 0.8574 - val_loss: 15.8441 - val_acc: 0.0213\n",
      "Epoch 3/150\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.1470 - acc: 0.8499 - val_loss: 15.8440 - val_acc: 0.0213\n",
      "Epoch 4/150\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.1339 - acc: 0.8528 - val_loss: 16.0721 - val_acc: 0.0071\n",
      "Epoch 5/150\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.1580 - acc: 0.8437 - val_loss: 16.0721 - val_acc: 0.0071\n",
      "Epoch 6/150\n",
      "2405/2405 [==============================] - 17s 7ms/step - loss: 1.1966 - acc: 0.8349 - val_loss: 16.0725 - val_acc: 0.0071\n",
      "Epoch 7/150\n",
      "2405/2405 [==============================] - 16s 7ms/step - loss: 1.7706 - acc: 0.7148 - val_loss: 15.3466 - val_acc: 0.0496\n",
      "Epoch 8/150\n",
      "2405/2405 [==============================] - 23s 9ms/step - loss: 1.5519 - acc: 0.7443 - val_loss: 16.1957 - val_acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "2405/2405 [==============================] - 38s 16ms/step - loss: 1.2068 - acc: 0.8387 - val_loss: 16.1955 - val_acc: 0.0000e+00\n",
      "Epoch 10/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.1470 - acc: 0.8516 - val_loss: 16.1950 - val_acc: 0.0000e+00\n",
      "Epoch 11/150\n",
      "2405/2405 [==============================] - 30s 12ms/step - loss: 1.1374 - acc: 0.8565 - val_loss: 16.1944 - val_acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "2405/2405 [==============================] - 28s 12ms/step - loss: 1.1295 - acc: 0.8578 - val_loss: 16.1932 - val_acc: 0.0000e+00\n",
      "Epoch 13/150\n",
      "2405/2405 [==============================] - 30s 13ms/step - loss: 1.1262 - acc: 0.8565 - val_loss: 16.1924 - val_acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 1.1265 - acc: 0.8561 - val_loss: 16.1915 - val_acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "2405/2405 [==============================] - 33s 14ms/step - loss: 1.1335 - acc: 0.8570 - val_loss: 16.1906 - val_acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      "2405/2405 [==============================] - 32s 13ms/step - loss: 1.1178 - acc: 0.8582 - val_loss: 16.1897 - val_acc: 0.0000e+00\n",
      "Epoch 17/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1138 - acc: 0.8595 - val_loss: 16.1886 - val_acc: 0.0000e+00\n",
      "Epoch 18/150\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 1.1121 - acc: 0.8599 - val_loss: 16.1877 - val_acc: 0.0000e+00\n",
      "Epoch 19/150\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 1.1106 - acc: 0.8590 - val_loss: 16.1867 - val_acc: 0.0000e+00\n",
      "Epoch 20/150\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 1.1106 - acc: 0.8595 - val_loss: 16.1860 - val_acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "2405/2405 [==============================] - 28s 12ms/step - loss: 1.1085 - acc: 0.8599 - val_loss: 16.0707 - val_acc: 0.0071\n",
      "Epoch 22/150\n",
      "2405/2405 [==============================] - 29s 12ms/step - loss: 1.1070 - acc: 0.8599 - val_loss: 16.1841 - val_acc: 0.0000e+00\n",
      "Epoch 23/150\n",
      "2405/2405 [==============================] - 38s 16ms/step - loss: 1.1067 - acc: 0.8586 - val_loss: 16.1833 - val_acc: 0.0000e+00\n",
      "Epoch 24/150\n",
      "2405/2405 [==============================] - 44s 18ms/step - loss: 1.1099 - acc: 0.8590 - val_loss: 16.0681 - val_acc: 0.0071\n",
      "Epoch 25/150\n",
      "2405/2405 [==============================] - 42s 17ms/step - loss: 1.1038 - acc: 0.8599 - val_loss: 16.0671 - val_acc: 0.0071\n",
      "Epoch 26/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.1024 - acc: 0.8595 - val_loss: 16.0661 - val_acc: 0.0071\n",
      "Epoch 27/150\n",
      "2405/2405 [==============================] - 42s 18ms/step - loss: 1.1023 - acc: 0.8595 - val_loss: 16.0653 - val_acc: 0.0071\n",
      "Epoch 28/150\n",
      "2405/2405 [==============================] - 43s 18ms/step - loss: 1.1001 - acc: 0.8599 - val_loss: 16.0644 - val_acc: 0.0071\n",
      "Epoch 29/150\n",
      "2405/2405 [==============================] - 40s 17ms/step - loss: 1.1019 - acc: 0.8603 - val_loss: 16.0637 - val_acc: 0.0071\n",
      "Epoch 30/150\n",
      "2405/2405 [==============================] - 42s 18ms/step - loss: 1.1115 - acc: 0.8574 - val_loss: 16.0630 - val_acc: 0.0071\n",
      "Epoch 31/150\n",
      "2405/2405 [==============================] - 46s 19ms/step - loss: 1.1101 - acc: 0.8574 - val_loss: 16.0627 - val_acc: 0.0071\n",
      "Epoch 32/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.1304 - acc: 0.8524 - val_loss: 15.9488 - val_acc: 0.0142\n",
      "Epoch 33/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.1385 - acc: 0.8495 - val_loss: 16.0633 - val_acc: 0.0071\n",
      "Epoch 34/150\n",
      "2405/2405 [==============================] - 39s 16ms/step - loss: 1.1645 - acc: 0.8449 - val_loss: 15.9531 - val_acc: 0.0142\n",
      "Epoch 35/150\n",
      "2405/2405 [==============================] - 40s 16ms/step - loss: 1.1450 - acc: 0.8453 - val_loss: 15.9493 - val_acc: 0.0142\n",
      "Epoch 36/150\n",
      "2405/2405 [==============================] - 40s 17ms/step - loss: 1.1466 - acc: 0.8482 - val_loss: 15.7214 - val_acc: 0.0284\n",
      "Epoch 37/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.1756 - acc: 0.8391 - val_loss: 15.7990 - val_acc: 0.0213\n",
      "Epoch 38/150\n",
      "2405/2405 [==============================] - 39s 16ms/step - loss: 1.1739 - acc: 0.8395 - val_loss: 15.8366 - val_acc: 0.0213\n",
      "Epoch 39/150\n",
      "2405/2405 [==============================] - 37s 15ms/step - loss: 1.1473 - acc: 0.8495 - val_loss: 15.8182 - val_acc: 0.0213\n",
      "Epoch 40/150\n",
      "2405/2405 [==============================] - 37s 15ms/step - loss: 1.1609 - acc: 0.8432 - val_loss: 15.9506 - val_acc: 0.0142\n",
      "Epoch 41/150\n",
      "2405/2405 [==============================] - 37s 15ms/step - loss: 1.1438 - acc: 0.8453 - val_loss: 15.7218 - val_acc: 0.0284\n",
      "Epoch 42/150\n",
      "2405/2405 [==============================] - 37s 15ms/step - loss: 1.1495 - acc: 0.8441 - val_loss: 15.6072 - val_acc: 0.0355\n",
      "Epoch 43/150\n",
      "2405/2405 [==============================] - 44s 18ms/step - loss: 1.1161 - acc: 0.8545 - val_loss: 15.7209 - val_acc: 0.0284\n",
      "Epoch 44/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.1123 - acc: 0.8553 - val_loss: 15.4913 - val_acc: 0.0426\n",
      "Epoch 45/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.1098 - acc: 0.8561 - val_loss: 15.6049 - val_acc: 0.0355\n",
      "Epoch 46/150\n",
      "2405/2405 [==============================] - 46s 19ms/step - loss: 1.1083 - acc: 0.8565 - val_loss: 15.3754 - val_acc: 0.0496\n",
      "Epoch 47/150\n",
      "2405/2405 [==============================] - 42s 17ms/step - loss: 1.1010 - acc: 0.8570 - val_loss: 15.4414 - val_acc: 0.0426\n",
      "Epoch 48/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.1417 - acc: 0.8474 - val_loss: 15.7173 - val_acc: 0.0284\n",
      "Epoch 49/150\n",
      "2405/2405 [==============================] - 39s 16ms/step - loss: 1.1147 - acc: 0.8545 - val_loss: 15.3742 - val_acc: 0.0496\n",
      "Epoch 50/150\n",
      "2405/2405 [==============================] - 39s 16ms/step - loss: 1.0831 - acc: 0.8603 - val_loss: 15.2587 - val_acc: 0.0567\n",
      "Epoch 51/150\n",
      "2405/2405 [==============================] - 38s 16ms/step - loss: 1.0904 - acc: 0.8578 - val_loss: 15.3719 - val_acc: 0.0496\n",
      "Epoch 52/150\n",
      "2405/2405 [==============================] - 37s 15ms/step - loss: 1.0822 - acc: 0.8607 - val_loss: 15.3711 - val_acc: 0.0496\n",
      "Epoch 53/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1045 - acc: 0.8553 - val_loss: 15.2559 - val_acc: 0.0567\n",
      "Epoch 54/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1141 - acc: 0.8528 - val_loss: 15.1045 - val_acc: 0.0638\n",
      "Epoch 55/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0917 - acc: 0.8574 - val_loss: 15.4849 - val_acc: 0.0426\n",
      "Epoch 56/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0984 - acc: 0.8565 - val_loss: 14.7175 - val_acc: 0.0851\n",
      "Epoch 57/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0867 - acc: 0.8582 - val_loss: 14.7975 - val_acc: 0.0851\n",
      "Epoch 58/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0785 - acc: 0.8603 - val_loss: 14.9113 - val_acc: 0.0780\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0828 - acc: 0.8595 - val_loss: 15.5954 - val_acc: 0.0355\n",
      "Epoch 60/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0783 - acc: 0.8590 - val_loss: 14.9088 - val_acc: 0.0780\n",
      "Epoch 61/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0785 - acc: 0.8578 - val_loss: 15.5939 - val_acc: 0.0355\n",
      "Epoch 62/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0932 - acc: 0.8570 - val_loss: 15.1362 - val_acc: 0.0638\n",
      "Epoch 63/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0877 - acc: 0.8557 - val_loss: 15.2504 - val_acc: 0.0567\n",
      "Epoch 64/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1225 - acc: 0.8449 - val_loss: 14.9084 - val_acc: 0.0780\n",
      "Epoch 65/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1498 - acc: 0.8378 - val_loss: 14.4063 - val_acc: 0.1064\n",
      "Epoch 66/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1147 - acc: 0.8453 - val_loss: 15.0245 - val_acc: 0.0709\n",
      "Epoch 67/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0970 - acc: 0.8507 - val_loss: 15.1324 - val_acc: 0.0638\n",
      "Epoch 68/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0811 - acc: 0.8541 - val_loss: 15.0199 - val_acc: 0.0709\n",
      "Epoch 69/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0695 - acc: 0.8565 - val_loss: 14.7946 - val_acc: 0.0851\n",
      "Epoch 70/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0827 - acc: 0.8570 - val_loss: 14.9079 - val_acc: 0.0780\n",
      "Epoch 71/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0842 - acc: 0.8545 - val_loss: 14.9077 - val_acc: 0.0780\n",
      "Epoch 72/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0859 - acc: 0.8545 - val_loss: 14.6787 - val_acc: 0.0922\n",
      "Epoch 73/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0906 - acc: 0.8516 - val_loss: 14.6747 - val_acc: 0.0922\n",
      "Epoch 74/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0954 - acc: 0.8532 - val_loss: 14.3358 - val_acc: 0.1135\n",
      "Epoch 75/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0756 - acc: 0.8574 - val_loss: 14.9071 - val_acc: 0.0780\n",
      "Epoch 76/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0798 - acc: 0.8565 - val_loss: 15.0203 - val_acc: 0.0709\n",
      "Epoch 77/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0775 - acc: 0.8557 - val_loss: 14.5165 - val_acc: 0.0993\n",
      "Epoch 78/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0774 - acc: 0.8545 - val_loss: 14.5624 - val_acc: 0.0993\n",
      "Epoch 79/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0957 - acc: 0.8482 - val_loss: 15.3628 - val_acc: 0.0496\n",
      "Epoch 80/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0921 - acc: 0.8536 - val_loss: 14.6769 - val_acc: 0.0922\n",
      "Epoch 81/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0705 - acc: 0.8590 - val_loss: 14.6762 - val_acc: 0.0922\n",
      "Epoch 82/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0785 - acc: 0.8586 - val_loss: 15.0181 - val_acc: 0.0709\n",
      "Epoch 83/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0656 - acc: 0.8603 - val_loss: 14.7885 - val_acc: 0.0851\n",
      "Epoch 84/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.4951 - acc: 0.7563 - val_loss: 14.4529 - val_acc: 0.1064\n",
      "Epoch 85/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.1337 - acc: 0.8482 - val_loss: 14.2238 - val_acc: 0.1206\n",
      "Epoch 86/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0851 - acc: 0.8565 - val_loss: 14.3415 - val_acc: 0.1135\n",
      "Epoch 87/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0743 - acc: 0.8607 - val_loss: 14.3370 - val_acc: 0.1135\n",
      "Epoch 88/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0715 - acc: 0.8607 - val_loss: 14.3365 - val_acc: 0.1135\n",
      "Epoch 89/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0707 - acc: 0.8607 - val_loss: 14.3360 - val_acc: 0.1135\n",
      "Epoch 90/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0704 - acc: 0.8607 - val_loss: 14.1701 - val_acc: 0.1206\n",
      "Epoch 91/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0699 - acc: 0.8603 - val_loss: 14.5636 - val_acc: 0.0993\n",
      "Epoch 92/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0873 - acc: 0.8553 - val_loss: 14.1063 - val_acc: 0.1277\n",
      "Epoch 93/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0796 - acc: 0.8578 - val_loss: 14.1062 - val_acc: 0.1277\n",
      "Epoch 94/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0695 - acc: 0.8599 - val_loss: 14.1057 - val_acc: 0.1277\n",
      "Epoch 95/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0796 - acc: 0.8565 - val_loss: 14.2197 - val_acc: 0.1206\n",
      "Epoch 96/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0723 - acc: 0.8586 - val_loss: 14.2193 - val_acc: 0.1206\n",
      "Epoch 97/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0737 - acc: 0.8561 - val_loss: 14.6233 - val_acc: 0.0922\n",
      "Epoch 98/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0792 - acc: 0.8561 - val_loss: 14.8034 - val_acc: 0.0780\n",
      "Epoch 99/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0737 - acc: 0.8586 - val_loss: 14.1041 - val_acc: 0.1277\n",
      "Epoch 100/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0730 - acc: 0.8578 - val_loss: 14.2180 - val_acc: 0.1206\n",
      "Epoch 101/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0657 - acc: 0.8599 - val_loss: 14.1032 - val_acc: 0.1277\n",
      "Epoch 102/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0666 - acc: 0.8590 - val_loss: 14.2172 - val_acc: 0.1206\n",
      "Epoch 103/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0626 - acc: 0.8590 - val_loss: 14.1026 - val_acc: 0.1277\n",
      "Epoch 104/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0646 - acc: 0.8599 - val_loss: 14.4451 - val_acc: 0.1064\n",
      "Epoch 105/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0692 - acc: 0.8595 - val_loss: 14.2119 - val_acc: 0.1206\n",
      "Epoch 106/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0590 - acc: 0.8595 - val_loss: 14.5589 - val_acc: 0.0993\n",
      "Epoch 107/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.6064 - acc: 0.7310 - val_loss: 15.4795 - val_acc: 0.0426\n",
      "Epoch 108/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.1464 - acc: 0.8374 - val_loss: 15.0221 - val_acc: 0.0709\n",
      "Epoch 109/150\n",
      "2405/2405 [==============================] - 37s 15ms/step - loss: 1.0876 - acc: 0.8557 - val_loss: 15.1361 - val_acc: 0.0638\n",
      "Epoch 110/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0957 - acc: 0.8557 - val_loss: 15.2504 - val_acc: 0.0567\n",
      "Epoch 111/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0885 - acc: 0.8570 - val_loss: 15.5023 - val_acc: 0.0355\n",
      "Epoch 112/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0723 - acc: 0.8599 - val_loss: 15.2494 - val_acc: 0.0567\n",
      "Epoch 113/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0770 - acc: 0.8582 - val_loss: 15.2489 - val_acc: 0.0567\n",
      "Epoch 114/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0697 - acc: 0.8595 - val_loss: 15.3505 - val_acc: 0.0496\n",
      "Epoch 115/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0675 - acc: 0.8607 - val_loss: 15.2480 - val_acc: 0.0567\n",
      "Epoch 116/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0673 - acc: 0.8599 - val_loss: 15.3619 - val_acc: 0.0496\n",
      "Epoch 117/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0599 - acc: 0.8607 - val_loss: 15.3615 - val_acc: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0659 - acc: 0.8603 - val_loss: 15.2467 - val_acc: 0.0567\n",
      "Epoch 119/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0622 - acc: 0.8603 - val_loss: 15.3606 - val_acc: 0.0496\n",
      "Epoch 120/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0728 - acc: 0.8582 - val_loss: 15.3605 - val_acc: 0.0496\n",
      "Epoch 121/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0654 - acc: 0.8599 - val_loss: 15.4744 - val_acc: 0.0426\n",
      "Epoch 122/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0644 - acc: 0.8607 - val_loss: 15.4739 - val_acc: 0.0426\n",
      "Epoch 123/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0636 - acc: 0.8603 - val_loss: 15.5881 - val_acc: 0.0355\n",
      "Epoch 124/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0713 - acc: 0.8590 - val_loss: 15.8163 - val_acc: 0.0213\n",
      "Epoch 125/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0572 - acc: 0.8603 - val_loss: 15.5872 - val_acc: 0.0355\n",
      "Epoch 126/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0695 - acc: 0.8599 - val_loss: 15.5543 - val_acc: 0.0355\n",
      "Epoch 127/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0618 - acc: 0.8607 - val_loss: 15.4719 - val_acc: 0.0426\n",
      "Epoch 128/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0546 - acc: 0.8603 - val_loss: 15.4715 - val_acc: 0.0426\n",
      "Epoch 129/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0619 - acc: 0.8599 - val_loss: 15.4714 - val_acc: 0.0426\n",
      "Epoch 130/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0545 - acc: 0.8603 - val_loss: 15.4709 - val_acc: 0.0426\n",
      "Epoch 131/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0738 - acc: 0.8574 - val_loss: 15.4707 - val_acc: 0.0426\n",
      "Epoch 132/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0983 - acc: 0.8499 - val_loss: 15.4711 - val_acc: 0.0426\n",
      "Epoch 133/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.1692 - acc: 0.8312 - val_loss: 15.8161 - val_acc: 0.0213\n",
      "Epoch 134/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1211 - acc: 0.8453 - val_loss: 15.2447 - val_acc: 0.0567\n",
      "Epoch 135/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1062 - acc: 0.8503 - val_loss: 15.3589 - val_acc: 0.0496\n",
      "Epoch 136/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0733 - acc: 0.8578 - val_loss: 15.4727 - val_acc: 0.0426\n",
      "Epoch 137/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.0672 - acc: 0.8595 - val_loss: 15.5163 - val_acc: 0.0355\n",
      "Epoch 138/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1828 - acc: 0.8283 - val_loss: 15.3602 - val_acc: 0.0496\n",
      "Epoch 139/150\n",
      "2405/2405 [==============================] - 35s 15ms/step - loss: 1.2457 - acc: 0.8100 - val_loss: 15.7072 - val_acc: 0.0284\n",
      "Epoch 140/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.1080 - acc: 0.8470 - val_loss: 15.5937 - val_acc: 0.0355\n",
      "Epoch 141/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.0903 - acc: 0.8511 - val_loss: 15.5930 - val_acc: 0.0355\n",
      "Epoch 142/150\n",
      "2405/2405 [==============================] - 40s 17ms/step - loss: 1.0879 - acc: 0.8524 - val_loss: 15.4785 - val_acc: 0.0426\n",
      "Epoch 143/150\n",
      "2405/2405 [==============================] - 38s 16ms/step - loss: 1.0778 - acc: 0.8570 - val_loss: 15.8209 - val_acc: 0.0213\n",
      "Epoch 144/150\n",
      "2405/2405 [==============================] - 36s 15ms/step - loss: 1.0787 - acc: 0.8557 - val_loss: 15.1387 - val_acc: 0.0638\n",
      "Epoch 145/150\n",
      "2405/2405 [==============================] - 42s 18ms/step - loss: 1.0570 - acc: 0.8607 - val_loss: 15.5914 - val_acc: 0.0355\n",
      "Epoch 146/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.0599 - acc: 0.8611 - val_loss: 15.4762 - val_acc: 0.0426\n",
      "Epoch 147/150\n",
      "2405/2405 [==============================] - 40s 17ms/step - loss: 1.0586 - acc: 0.8611 - val_loss: 15.4754 - val_acc: 0.0426\n",
      "Epoch 148/150\n",
      "2405/2405 [==============================] - 42s 17ms/step - loss: 1.0590 - acc: 0.8607 - val_loss: 15.7033 - val_acc: 0.0284\n",
      "Epoch 149/150\n",
      "2405/2405 [==============================] - 45s 19ms/step - loss: 1.0598 - acc: 0.8599 - val_loss: 15.4747 - val_acc: 0.0426\n",
      "Epoch 150/150\n",
      "2405/2405 [==============================] - 41s 17ms/step - loss: 1.0640 - acc: 0.8599 - val_loss: 15.5882 - val_acc: 0.0355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c35492d68>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tensor, y_labels, validation_data=(X_test_all, y_test_enc), epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BURADA 12.77% GELDI, EN IYI MODEL BU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
